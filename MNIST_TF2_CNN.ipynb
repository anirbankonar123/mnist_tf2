{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Accuracy CNN for MNIST in TF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28 , 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 , 28 , 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 32s 539us/sample - loss: 0.2301 - accuracy: 0.9289\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 31s 525us/sample - loss: 0.0523 - accuracy: 0.9841\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 504us/sample - loss: 0.0349 - accuracy: 0.9894\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 30s 500us/sample - loss: 0.0266 - accuracy: 0.9918\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 30s 500us/sample - loss: 0.0204 - accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 30s 500us/sample - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 30s 507us/sample - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 30s 506us/sample - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 30s 503us/sample - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 30s 508us/sample - loss: 0.0076 - accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f160ea559b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now compile and print out a summary of our model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 192us/sample - loss: 0.0269 - accuracy: 0.9920\n",
      "0.992\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.9531767e-11 1.2401433e-08 1.0000000e+00 1.1737353e-10 1.5589965e-11\n",
      "  3.5331417e-16 5.0818658e-16 2.1414994e-09 2.9210092e-09 1.0501742e-11]]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirban/anaconda3/envs/tf2/lib/python3.6/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f15a4470550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = tf.keras.preprocessing.image \n",
    "\n",
    "\n",
    "temp_img=image.load_img(\"/home/anirban/Downloads/digit2.png\",grayscale=True,target_size=(28,28)) \n",
    "temp_img=image.img_to_array(temp_img)\n",
    "train_img=temp_img\n",
    "#converting train images to array and applying mean subtraction processing\n",
    "train_img=np.array(train_img)\n",
    "train_img = train_img.reshape((1, 28 , 28 , 1)) \n",
    "train_img = train_img.astype('float32') / 255\n",
    "\n",
    "lab = model.predict(train_img) \n",
    "print(lab) \n",
    "print(np.argmax(lab))\n",
    "\n",
    "\n",
    "img = image.load_img(\"/home/anirban/Downloads/digit2.png\", target_size=(28, 28))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
